import pandas as pd
import numpy as np
import xgboost as xgb
from sklearn.metrics import mean_absolute_error
from sklearn.linear_model import Ridge
from sklearn.preprocessing import PolynomialFeatures
import joblib
from pathlib import Path
import logging
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from scipy.stats import norm
from datetime import datetime
import warnings
import optuna
from optuna.visualization import plot_optimization_history, plot_param_importances
from concurrent.futures import ThreadPoolExecutor
import multiprocessing as mp
import json
import sys

warnings.filterwarnings('ignore')

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class AdaptiveVolatilityCalibrator:
    """
    ML-based volatility calibration using XGBoost to learn optimal multiplier.
    Replaces hardcoded edge bins and gap calculations.
    """
    
    def __init__(self):
        self.model = None
        self.is_fitted = False
        
    def fit(self, bet_features, actual_outcomes):
        """
        Learn volatility calibration from validation data.
        
        Args:
            bet_features: DataFrame with columns: edge, mov_std, cover_prob, etc.
            actual_outcomes: Binary outcomes (1=win, 0=loss)
        """
        if len(bet_features) < 30:
            return False, None
            
        # Train small XGBoost model to predict win probability
        params = {
            'objective': 'binary:logistic',
            'tree_method': 'hist',
            'device': 'cuda',
            'max_depth': 3,
            'learning_rate': 0.1,
            'n_estimators': 50,
            'seed': 42
        }
        
        self.model = xgb.XGBClassifier(**params)
        self.model.fit(bet_features, actual_outcomes)
        self.is_fitted = True
        
        # Calculate calibration error
        predicted_probs = self.model.predict_proba(bet_features)[:, 1]
        expected_probs = bet_features['cover_prob'].values
        
        # Estimate required volatility multiplier from calibration error
        calibration_error = np.mean(expected_probs - predicted_probs)
        
        # Convert calibration error to multiplier
        if calibration_error > 0:  # Overconfident
            multiplier = 1.0 + calibration_error * 5.0
        else:  # Underconfident
            multiplier = max(0.8, 1.0 + calibration_error * 3.0)
            
        return True, multiplier


class AdaptivePushPredictor:
    """
    ML model to predict push probability instead of using hardcoded push_window.
    """
    
    def __init__(self):
        self.model = None
        self.is_fitted = False
        
    def fit(self, spread_data, push_outcomes):
        """
        Learn push probability from historical data.
        
        Args:
            spread_data: DataFrame with spread, spread_magnitude, mov_std, etc.
            push_outcomes: Binary (1=push, 0=not push)
        """
        if len(spread_data) < 50 or push_outcomes.sum() < 5:
            return False
            
        params = {
            'objective': 'binary:logistic',
            'tree_method': 'hist',
            'device': 'cuda',
            'max_depth': 2,
            'learning_rate': 0.1,
            'n_estimators': 30,
            'seed': 42
        }
        
        self.model = xgb.XGBClassifier(**params)
        self.model.fit(spread_data, push_outcomes)
        self.is_fitted = True
        return True
    
    def predict_push_prob(self, spread, spread_magnitude, mov_std, fallback_window=0.5):
        """
        Predict push probability for given bet.
        
        Args:
            spread: Spread value
            spread_magnitude: Absolute value of spread
            mov_std: Predicted standard deviation
            fallback_window: HPO-optimized fallback window for norm calculation
        """
        if not self.is_fitted:
            # Fallback to norm-based calculation with HPO-optimized window
            push_window = fallback_window
            return norm.cdf(-spread + push_window, loc=0, scale=mov_std) - \
                   norm.cdf(-spread - push_window, loc=0, scale=mov_std)
        
        features = pd.DataFrame({
            'spread': [spread],
            'spread_magnitude': [spread_magnitude],
            'mov_std': [mov_std]
        })
        
        return self.model.predict_proba(features)[0, 1]


class GPUSpreadBettingModel:
    """
    GPU-accelerated XGBoost spread betting model with ML-based adaptive systems.
    ALL hardcoded thresholds replaced with learned functions.
    """
    
    def __init__(self, data_path, output_dir='./spread_model_output', 
                 initial_bankroll=100, 
                 # Hyperparameters to optimize
                 max_kelly_fraction=0.05,
                 min_edge_threshold=0.05,
                 blend_factor=0.6,
                 conformal_alpha=0.10,
                 max_depth=5,
                 learning_rate=0.02,
                 n_estimators=300,
                 feature_windows=None,
                 volatility_multiplier_base=1.5,
                 kelly_edge_threshold_1=0.055,
                 kelly_edge_threshold_2=0.075,
                 kelly_edge_threshold_3=0.10,
                 kelly_multiplier_1=0.25,
                 kelly_multiplier_2=0.40,
                 kelly_multiplier_3=0.60,
                 subsample=0.7,
                 colsample_bytree=0.7,
                 reg_alpha=1.0,
                 reg_lambda=1.0,
                 min_child_weight=50,
                 fallback_push_window=0.5,
                 trial=None):  # For Optuna pruning
        
        self.data_path = data_path
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        
        # Optuna trial for pruning
        self.trial = trial
        
        # Models
        self.mean_models = {}
        self.q16_models = {}
        self.q84_models = {}
        self.conformal_quantiles = {}
        
        # Adaptive ML systems (Kelly adjuster removed - HPO handles this better)
        self.volatility_calibrator = AdaptiveVolatilityCalibrator()
        self.push_predictor = AdaptivePushPredictor()
        
        # Bankroll management - OPTIMIZABLE
        self.initial_bankroll = initial_bankroll
        self.current_bankroll = initial_bankroll
        self.max_kelly_fraction = max_kelly_fraction
        self.min_edge_threshold = min_edge_threshold
        
        # Uncertainty estimation - OPTIMIZABLE
        self.blend_factor = blend_factor
        self.conformal_alpha = conformal_alpha
        self.volatility_multiplier_base = volatility_multiplier_base
        
        # Model hyperparameters - OPTIMIZABLE
        self.max_depth = max_depth
        self.learning_rate = learning_rate
        self.n_estimators = n_estimators
        self.subsample = subsample
        self.colsample_bytree = colsample_bytree
        self.reg_alpha = reg_alpha
        self.reg_lambda = reg_lambda
        self.min_child_weight = min_child_weight
        
        # Feature engineering - OPTIMIZABLE
        self.feature_windows = feature_windows or [5, 10, 20]
        
        # Kelly adjustment thresholds - OPTIMIZABLE (used for initial training)
        self.kelly_edge_threshold_1 = kelly_edge_threshold_1
        self.kelly_edge_threshold_2 = kelly_edge_threshold_2
        self.kelly_edge_threshold_3 = kelly_edge_threshold_3
        self.kelly_multiplier_1 = kelly_multiplier_1
        self.kelly_multiplier_2 = kelly_multiplier_2
        self.kelly_multiplier_3 = kelly_multiplier_3
        
        # Push predictor fallback - OPTIMIZABLE
        self.fallback_push_window = fallback_push_window
        
        # Performance tracking
        self.betting_history = []
        self.push_history = []
        self.volatility_calibration = {}
        self.recent_performance = []
        
        # Feature importance tracking
        self.feature_importances = {}
        
        # Quiet mode for optimization
        self.quiet_mode = False

    def set_quiet_mode(self, quiet=True):
        """Enable/disable logging for optimization runs"""
        self.quiet_mode = quiet
        if quiet:
            logger.setLevel(logging.WARNING)
        else:
            logger.setLevel(logging.INFO)

    def get_conformal_interval(self, calibration_residuals):
        """Calculate conformal prediction quantile - uses self.conformal_alpha"""
        n = len(calibration_residuals)
        quantile_level = np.ceil((1 - self.conformal_alpha) * (n + 1)) / n
        quantile = np.quantile(calibration_residuals, quantile_level)
        return quantile

    def _calibrate_conformal_on_holdout(self, calibration_df, mean_model, q16_model, q84_model, 
                                        feature_cols, numeric_cols, categorical_cols):
        """Use separate calibration set for conformal prediction intervals"""
        if len(calibration_df) < 30:
            if not self.quiet_mode:
                logger.warning("Insufficient calibration data - skipping conformal calibration")
            return None
        
        X_cal = self._prepare_features(calibration_df, numeric_cols, categorical_cols)
        y_cal_error = calibration_df['mov_target'].values
        
        # GPU prediction
        dmatrix_cal = xgb.DMatrix(X_cal)
        cal_pred_error = mean_model.predict(dmatrix_cal)
        cal_residuals = np.abs(y_cal_error - cal_pred_error)
        
        conformal_q = self.get_conformal_interval(cal_residuals)
        
        if not self.quiet_mode:
            logger.info(f"  Conformal calibration: {(1-self.conformal_alpha)*100:.0f}% quantile = {conformal_q:.2f} points")
        
        return conformal_q

    def _combine_quantile_and_conformal(self, quantile_std, conformal_quantile):
        """Combine using self.blend_factor"""
        conformal_std = conformal_quantile / 1.645
        combined_std = self.blend_factor * quantile_std + (1 - self.blend_factor) * conformal_std
        return combined_std
        
    def load_and_prepare_data(self):
        """Load data and engineer features"""
        if not self.quiet_mode:
            logger.info(f"Loading data from {self.data_path}")
        
        df = pd.read_parquet(self.data_path)
        df = df.drop_duplicates(subset=['gameId'], keep='first')
        
        # Core temporal features
        df['date'] = pd.to_datetime(df['startDate'])
        df['season'] = df['date'].dt.year
        df.loc[df['date'].dt.month >= 7, 'season'] += 1
        df['season_numeric'] = df['season'] - df['season'].min()
        df['day_of_week'] = df['date'].dt.dayofweek
        df['month'] = df['date'].dt.month
        df['week_of_season'] = ((df['date'] - df.groupby('season')['date'].transform('min')).dt.days / 7).astype(int)
        
        # Target is spread ERROR
        df['spread_error'] = df['actual_margin'] - df['team_spread']
        df['mov_target'] = df['spread_error']
        df['is_push'] = (np.abs(df['actual_margin'] - df['team_spread']) < 0.01).astype(int)
        
        # Market efficiency indicators
        if 'homeMoneyline' in df.columns and 'awayMoneyline' in df.columns:
            df['home_implied_prob'] = self._moneyline_to_prob(df['homeMoneyline'])
            df['away_implied_prob'] = self._moneyline_to_prob(df['awayMoneyline'])
            df['market_inefficiency'] = abs(df['home_implied_prob'] + df['away_implied_prob'] - 1.0)
            df['value_indicator'] = df['market_inefficiency'] * abs(df['team_spread'])
        
        # Enhanced features with OPTIMIZABLE windows
        df = self._add_market_aware_features(df)
        df = self._add_volatility_features(df)
        
        return df
    
    def _moneyline_to_prob(self, moneyline):
        """Convert moneyline odds to implied probability"""
        return np.where(moneyline < 0, 
                       -moneyline / (-moneyline + 100),
                       100 / (moneyline + 100))
    
    def _add_market_aware_features(self, df):
        """Add features using OPTIMIZABLE windows"""
        df = df.sort_values(['team', 'date'])
        
        # Use self.feature_windows instead of hard-coded [5, 10, 20]
        for window in self.feature_windows:
            df[f'team_spread_bias_L{window}'] = (
                df.groupby(['season', 'team'])['spread_error']
                .transform(lambda x: x.rolling(window, min_periods=3).mean().shift(1))
            ).fillna(0)
            
            df[f'team_cover_rate_L{window}'] = (
                df.groupby(['season', 'team'])
                .apply(lambda x: ((x['spread_error'] > 0).rolling(window, min_periods=3).mean().shift(1)))
                .reset_index(level=[0,1], drop=True)
            ).fillna(0.5)
            
            df[f'opp_spread_bias_L{window}'] = (
                df.groupby(['season', 'opponent'])['spread_error']
                .transform(lambda x: -x.rolling(window, min_periods=3).mean().shift(1))
            ).fillna(0)
        
        # Spread magnitude features
        df['spread_magnitude'] = abs(df['team_spread'])
        df['is_close_spread'] = (df['spread_magnitude'] < 3).astype(int)
        df['is_large_spread'] = (df['spread_magnitude'] > 10).astype(int)
        
        df['spread_bucket'] = pd.cut(df['team_spread'], 
                                     bins=[-100, -14, -7, -3, 3, 7, 14, 100],
                                     labels=['huge_dog', 'big_dog', 'dog', 'close', 'fav', 'big_fav', 'huge_fav'])
        
        df['team_performance_in_bucket'] = (
            df.groupby(['team', 'spread_bucket'])['spread_error']
            .transform(lambda x: x.rolling(20, min_periods=3).mean().shift(1))
        ).fillna(0)
        
        return df
    
    def _add_volatility_features(self, df):
        """Add volatility features using OPTIMIZABLE windows"""
        for window in [10, 20]:
            df[f'team_spread_error_std_L{window}'] = (
                df.groupby(['season', 'team'])['spread_error']
                .transform(lambda x: x.rolling(window, min_periods=3).std().shift(1))
            ).fillna(7)
        
        df['is_primetime'] = df['day_of_week'].isin([4, 5, 6, 0]).astype(int)
        
        df['situational_volatility'] = df.groupby(['season', 'team', 'is_home'])['spread_error'].transform(
            lambda x: x.rolling(20, min_periods=5).std().shift(1)
        ).fillna(7)
        
        return df

    def _calibrate_volatility_on_validation(self, val_predictions_df, historical_preds_df=None):
        """
        ML-based volatility calibration using ALL available validation history.
        More robust than single-season training.
        
        Args:
            val_predictions_df: Current validation season results
            historical_preds_df: All previous seasons' results (for stability)
        """
        # Combine current validation data with all prior seasons' data
        if historical_preds_df is not None and not historical_preds_df.empty:
            all_val_data = pd.concat([val_predictions_df, historical_preds_df], ignore_index=True)
        else:
            all_val_data = val_predictions_df
        
        val_bets = all_val_data[all_val_data['bet_made']].copy()
        
        if len(val_bets) == 0:
            return self.volatility_multiplier_base
        
        decided = val_bets[val_bets['bet_correct'].notna()].copy()
        
        # Now we require more data, as we have more available (increased threshold)
        if len(decided) < 50:
            return self.volatility_multiplier_base
        
        # Prepare features for volatility calibration
        bet_features = decided[['edge', 'mov_std', 'cover_prob']].copy()
        actual_outcomes = decided['bet_correct'].astype(int)
        
        success, multiplier = self.volatility_calibrator.fit(bet_features, actual_outcomes)
        
        if success and multiplier is not None:
            # Blend with base multiplier for stability
            # Use higher confidence since we have more data
            confidence = min(1.0, len(decided) / 150)
            final_multiplier = confidence * multiplier + (1 - confidence) * self.volatility_multiplier_base
            
            if not self.quiet_mode:
                logger.info(f"  ‚úÖ Volatility calibrator trained on {len(decided)} bets (multi-season)")
                logger.info(f"     Multiplier: {final_multiplier:.3f} (confidence: {confidence:.2f})")
            
            return final_multiplier
        
        return self.volatility_multiplier_base
    
    def _train_push_predictor(self, historical_df):
        """Train ML model to predict push probability."""
        if len(historical_df) < 100:
            return False
        
        push_data = historical_df[['team_spread', 'spread_magnitude', 'mov_pred_std']].copy()
        push_data.columns = ['spread', 'spread_magnitude', 'mov_std']
        push_outcomes = historical_df['is_push'].values
        
        if push_outcomes.sum() < 5:
            return False
        
        return self.push_predictor.fit(push_data, push_outcomes)
    
    def _train_xgb_model(self, X_train, y_train, X_val, y_val, sample_weights,
                         objective, quantile_alpha=None, eval_metric='mae'):
        """
        Unified XGBoost training method - DRY refactoring.
        Trains a single XGBoost model on the GPU.
        """
        params = {
            'objective': objective,
            'tree_method': 'hist',
            'device': 'cuda',
            'learning_rate': self.learning_rate,
            'max_depth': self.max_depth,
            'min_child_weight': self.min_child_weight,
            'subsample': self.subsample,
            'colsample_bytree': self.colsample_bytree,
            'reg_alpha': self.reg_alpha,
            'reg_lambda': self.reg_lambda,
            'seed': 42
        }

        if objective == 'reg:quantileerror':
            params['quantile_alpha'] = quantile_alpha
            params['seed'] += int(quantile_alpha * 100)
        else:
            params['eval_metric'] = eval_metric
            
        dtrain = xgb.DMatrix(X_train, label=y_train, weight=sample_weights)
        
        if X_val is not None and len(X_val) > 0:
            dval = xgb.DMatrix(X_val, label=y_val)
            evals = [(dtrain, 'train'), (dval, 'valid')]
            
            model = xgb.train(
                params, 
                dtrain, 
                num_boost_round=500,
                evals=evals,
                early_stopping_rounds=50,
                verbose_eval=False
            )
        else:
            model = xgb.train(params, dtrain, num_boost_round=self.n_estimators)
        
        return model
        
    def get_feature_columns(self, df):
        """Get valid feature columns for modeling"""
        forbidden_cols = [
            'gameId', 'startDate', 'date', 'team', 'opponent', 'season',
            'points', 'opp_points', 'won', 'actual_margin', 'mov_target',
            'spread_target', 'spread_cover', 'is_push', 'spread_error',
            'spread_bucket'
        ]
        
        feature_cols = [col for col in df.columns if col not in forbidden_cols]
        numeric_cols = df[feature_cols].select_dtypes(include=[np.number]).columns.tolist()
        categorical_cols = df[feature_cols].select_dtypes(include=['category', 'object']).columns.tolist()
        
        return feature_cols, numeric_cols, categorical_cols
    
    def make_betting_decision(self, mov_mean, mov_std, spread, spread_magnitude, 
                              current_bankroll=None, edge_percentile=None):
        """
        Betting decision with HPO-optimized Kelly adjustments.
        Uses parametric thresholds optimized by Optuna (no ML Kelly adjuster - HPO is better).
        """
        if current_bankroll is None:
            current_bankroll = self.current_bankroll
        
        if mov_std <= 0 or current_bankroll < 1.0:
            return self._no_bet_decision(mov_mean, mov_std, 'invalid_inputs')
        
        team_cover_prob = 1 - norm.cdf(-spread, loc=mov_mean, scale=mov_std)
        opp_cover_prob = norm.cdf(-spread, loc=mov_mean, scale=mov_std)
        
        # Use ML-based push prediction with HPO-optimized fallback
        push_prob = self.push_predictor.predict_push_prob(
            spread, 
            spread_magnitude, 
            mov_std,
            self.fallback_push_window
        )
        
        fair_prob = 110/210
        
        team_edge = team_cover_prob - fair_prob
        opp_edge = opp_cover_prob - fair_prob
        
        if team_edge > self.min_edge_threshold and team_edge > opp_edge:
            edge = team_edge
            cover_prob = team_cover_prob
            decision_type = 'bet_team_cover'
        elif opp_edge > self.min_edge_threshold:
            edge = opp_edge
            cover_prob = opp_cover_prob
            decision_type = 'bet_opponent_cover'
        else:
            return self._no_bet_decision(mov_mean, mov_std, 'edge_below_threshold',
                                        team_edge, opp_edge, max(team_edge, opp_edge),
                                        team_cover_prob, push_prob)
        
        p = cover_prob * (1 - push_prob)
        q = (1 - cover_prob) * (1 - push_prob)
        b = 10/11
        
        kelly_fraction = (p * b - q) / b
        
        if kelly_fraction <= 0:
            return self._no_bet_decision(mov_mean, mov_std, 'negative_kelly',
                                        team_edge, opp_edge, edge, cover_prob, push_prob)
        
        # HPO-OPTIMIZED parametric Kelly adjustment (proven to be more robust than ML)
        # Optuna finds the optimal thresholds and multipliers
        kelly_multiplier = 1.0
        
        if edge < self.kelly_edge_threshold_1:
            kelly_multiplier *= self.kelly_multiplier_1
        elif edge < self.kelly_edge_threshold_2:
            kelly_multiplier *= self.kelly_multiplier_2
        elif edge < self.kelly_edge_threshold_3:
            kelly_multiplier *= self.kelly_multiplier_3
        
        kelly_fraction *= kelly_multiplier
        kelly_fraction = min(kelly_fraction, self.max_kelly_fraction)
        
        bet_amount = kelly_fraction * current_bankroll
        
        # Dynamic minimum bet based on bankroll
        min_bet = max(current_bankroll * 0.01, 1.0)
        if bet_amount < min_bet:
            return self._no_bet_decision(mov_mean, mov_std, 'bet_too_small',
                                        team_edge, opp_edge, edge, cover_prob, push_prob)
        
        return {
            'decision': decision_type,
            'reason': 'sufficient_edge',
            'bet_amount': bet_amount,
            'kelly_fraction': kelly_fraction,
            'kelly_multiplier': kelly_multiplier,
            'cover_prob': cover_prob,
            'push_prob': push_prob,
            'mov_mean': mov_mean,
            'mov_std': mov_std,
            'edge': edge,
            'team_edge': team_edge,
            'opp_edge': opp_edge
        }

    def _no_bet_decision(self, mov_mean, mov_std, reason, team_edge=0, opp_edge=0, 
                        edge=0, cover_prob=0, push_prob=0):
        """Helper to return consistent no-bet decision"""
        return {
            'decision': 'no_bet',
            'reason': reason,
            'bet_amount': 0,
            'kelly_fraction': 0,
            'kelly_multiplier': 0,
            'cover_prob': cover_prob,
            'push_prob': push_prob,
            'mov_mean': mov_mean,
            'mov_std': mov_std,
            'edge': edge,
            'team_edge': team_edge,
            'opp_edge': opp_edge
        }

    def _update_recent_performance(self, bet_amount, profit):
        """Track recent performance for adaptive betting"""
        self.recent_performance.append({
            'bet_amount': bet_amount,
            'profit': profit
        })
        if len(self.recent_performance) > 50:
            self.recent_performance.pop(0)
    
    def calculate_bet_outcome(self, decision, actual_margin, spread):
        """Calculate if bet won"""
        if abs(actual_margin - spread) < 0.01:
            return None, 0
        
        team_covered = (actual_margin + spread) > 0
        
        if decision['decision'] == 'bet_team_cover':
            bet_correct = team_covered
        elif decision['decision'] == 'bet_opponent_cover':
            bet_correct = not team_covered
        else:
            return None, 0
        
        if bet_correct:
            profit = decision['bet_amount'] * (100/110)
        else:
            profit = -decision['bet_amount']
        
        return bet_correct, profit

    def _calculate_sample_weights(self, df, test_season):
        """Calculate sample weights that emphasize recent data"""
        years_ago = test_season - df['season']
        weights = np.exp(-0.231 * years_ago)
        return weights
    
    def walk_forward_validation(self, df, feature_cols, numeric_cols, categorical_cols, 
                                test_seasons=None):
        """
        Walk-forward validation with:
        1. Parallel GPU training (3 models simultaneously)
        2. ML-based adaptive systems
        3. Optuna pruning support
        """
        if test_seasons is None:
            all_seasons = sorted(df['season'].unique())
            test_seasons = all_seasons[-5:] if len(all_seasons) >= 8 else all_seasons[-3:]
        
        if not self.quiet_mode:
            logger.info(f"\nTest seasons: {test_seasons}")
        
        all_predictions = []
        season_bankrolls = {test_seasons[0]: self.initial_bankroll}
        cumulative_roi_history = []
        
        for season_idx, test_season in enumerate(test_seasons):
            self.current_bankroll = season_bankrolls.get(test_season, self.initial_bankroll)
            
            val_season = test_season - 1
            cal_season = test_season - 2
            
            train_df = df[df['season'] < cal_season].copy()
            cal_df = df[df['season'] == cal_season].copy()
            val_df = df[df['season'] == val_season].copy()
            test_df = df[df['season'] == test_season].copy()
            
            if len(test_df) == 0:
                continue
            
            train_weights = self._calculate_sample_weights(train_df, test_season)
            
            X_train = self._prepare_features(train_df, numeric_cols, categorical_cols)
            X_val = self._prepare_features(val_df, numeric_cols, categorical_cols) if len(val_df) > 0 else None
            X_test = self._prepare_features(test_df, numeric_cols, categorical_cols)
            
            y_train_error = train_df['mov_target'].values
            y_val_error = val_df['mov_target'].values if len(val_df) > 0 else None
            y_test_error = test_df['mov_target'].values
            
            # ================================================================
            # PARALLEL GPU TRAINING - Train 3 models simultaneously
            # ================================================================
            def train_model_wrapper(model_type):
                """Helper for parallel training on same GPU."""
                if model_type == 'mean':
                    return self._train_xgb_model(
                        X_train, y_train_error, X_val, y_val_error,
                        sample_weights=train_weights.values,
                        objective='reg:squarederror',
                        eval_metric='mae'
                    )
                elif model_type == 'q16':
                    return self._train_xgb_model(
                        X_train, y_train_error, X_val, y_val_error,
                        sample_weights=train_weights.values,
                        objective='reg:quantileerror',
                        quantile_alpha=0.16
                    )
                elif model_type == 'q84':
                    return self._train_xgb_model(
                        X_train, y_train_error, X_val, y_val_error,
                        sample_weights=train_weights.values,
                        objective='reg:quantileerror',
                        quantile_alpha=0.84
                    )
            
            # Use ThreadPoolExecutor for parallel GPU training
            with ThreadPoolExecutor(max_workers=3) as executor:
                mean_future = executor.submit(train_model_wrapper, 'mean')
                q16_future = executor.submit(train_model_wrapper, 'q16')
                q84_future = executor.submit(train_model_wrapper, 'q84')
                
                mean_model = mean_future.result()
                q16_model = q16_future.result()
                q84_model = q84_future.result()
            
            self.mean_models[test_season] = mean_model
            self.q16_models[test_season] = q16_model
            self.q84_models[test_season] = q84_model
            
            # Store feature importance
            importance = mean_model.get_score(importance_type='gain')
            self.feature_importances[test_season] = importance
            
            # GPU predictions
            dtest = xgb.DMatrix(X_test)
            test_pred_error = mean_model.predict(dtest)
            test_pred_q16 = q16_model.predict(dtest)
            test_pred_q84 = q84_model.predict(dtest)
            
            raw_quantile_std = (test_pred_q84 - test_pred_q16) / 2.0
            raw_quantile_std = np.clip(raw_quantile_std, 3.0, 20.0)
            
            # Conformal calibration
            conformal_quantile = None
            if len(cal_df) >= 30:
                conformal_quantile = self._calibrate_conformal_on_holdout(
                    cal_df, mean_model, q16_model, q84_model,
                    feature_cols, numeric_cols, categorical_cols
                )
                self.conformal_quantiles[test_season] = conformal_quantile
            
            if conformal_quantile is not None:
                test_pred_std_base = np.array([
                    self._combine_quantile_and_conformal(q_std, conformal_quantile)
                    for q_std in raw_quantile_std
                ])
            else:
                test_pred_std_base = raw_quantile_std
            
            # ================================================================
            # ML-BASED ADAPTIVE CALIBRATION on validation set
            # ================================================================
            volatility_multiplier = 1.0
            
            if len(val_df) > 0:
                dval = xgb.DMatrix(X_val)
                val_pred_error = mean_model.predict(dval)
                val_pred_q16 = q16_model.predict(dval)
                val_pred_q84 = q84_model.predict(dval)
                val_raw_std = (val_pred_q84 - val_pred_q16) / 2.0
                val_raw_std = np.clip(val_raw_std, 3.0, 20.0)
                
                if conformal_quantile is not None:
                    val_pred_std = np.array([
                        self._combine_quantile_and_conformal(v_std, conformal_quantile)
                        for v_std in val_raw_std
                    ])
                else:
                    val_pred_std = val_raw_std
                
                val_spreads = val_df['team_spread'].values
                val_spread_magnitudes = val_df['spread_magnitude'].values
                val_pred_mov = val_spreads + val_pred_error
                
                # Get validation results with HPO-optimized Kelly
                val_results = []
                for idx in range(len(val_df)):
                    decision = self.make_betting_decision(
                        val_pred_mov[idx],
                        val_pred_std[idx],
                        val_spreads[idx],
                        val_spread_magnitudes[idx],
                        self.current_bankroll
                    )
                    
                    if decision['decision'] != 'no_bet':
                        bet_correct, _ = self.calculate_bet_outcome(
                            decision,
                            val_df['actual_margin'].iloc[idx],
                            val_spreads[idx]
                        )
                        decision['bet_correct'] = bet_correct
                        decision['bet_made'] = True
                    else:
                        decision['bet_made'] = False
                        decision['bet_correct'] = None
                    
                    val_results.append(decision)
                
                val_results_df = pd.DataFrame(val_results)
                
                # Train adaptive systems on ALL available validation history (more robust)
                # Combine with historical predictions from previous seasons
                historical_val_data = pd.concat(all_predictions, ignore_index=True) if all_predictions else pd.DataFrame()
                
                volatility_multiplier = self._calibrate_volatility_on_validation(
                    val_results_df,
                    historical_val_data
                )
                
                # Train push predictor on historical data (already multi-season)
                if season_idx > 0:
                    historical_preds = pd.concat(all_predictions, ignore_index=True)
                    push_trained = self._train_push_predictor(historical_preds)
                    if push_trained and not self.quiet_mode:
                        logger.info(f"  ‚úÖ Push predictor trained on {len(historical_preds)} games (multi-season)")
            else:
                volatility_multiplier = self.volatility_multiplier_base
            
            test_pred_std = test_pred_std_base * volatility_multiplier
            test_pred_std = np.clip(test_pred_std, 3.0, 28.0)
            
            test_spreads = test_df['team_spread'].values
            test_spread_magnitudes = test_df['spread_magnitude'].values
            test_pred_mov = test_spreads + test_pred_error
            
            # Make betting decisions on test set
            season_results = test_df[[
                'gameId', 'startDate', 'team', 'opponent', 'team_spread', 'actual_margin'
            ]].copy()
            
            season_results['is_push'] = test_df['is_push'].values
            season_results['pred_spread_error'] = test_pred_error
            season_results['mov_pred_mean'] = test_pred_mov
            season_results['mov_pred_std'] = test_pred_std
            season_results['spread_magnitude'] = test_spread_magnitudes
            season_results['season'] = test_season
            
            # Calculate edge percentiles
            temp_decisions = []
            for idx in range(len(season_results)):
                row = season_results.iloc[idx]
                temp_dec = self.make_betting_decision(
                    row['mov_pred_mean'], row['mov_pred_std'], 
                    row['team_spread'], row['spread_magnitude'],
                    self.current_bankroll
                )
                temp_decisions.append(temp_dec['edge'])
            
            edge_percentiles = np.array([
                (np.array(temp_decisions) < edge).mean() 
                for edge in temp_decisions
            ])
            
            # Final betting decisions with HPO-optimized parameters
            betting_decisions = []
            running_bankroll = self.current_bankroll
            
            for idx in range(len(season_results)):
                row = season_results.iloc[idx]
                
                decision = self.make_betting_decision(
                    row['mov_pred_mean'],
                    row['mov_pred_std'],
                    row['team_spread'],
                    row['spread_magnitude'],
                    running_bankroll,
                    edge_percentile=edge_percentiles[idx]
                )
                
                if decision['decision'] != 'no_bet':
                    bet_correct, profit = self.calculate_bet_outcome(
                        decision,
                        row['actual_margin'],
                        row['team_spread']
                    )
                    
                    if bet_correct is None:
                        decision['bet_correct'] = None
                        decision['bet_profit'] = 0
                    else:
                        decision['bet_correct'] = bet_correct
                        decision['bet_profit'] = profit
                        running_bankroll += profit
                        
                        self._update_recent_performance(decision['bet_amount'], profit)
                        
                        if running_bankroll <= 0:
                            running_bankroll = 0
                else:
                    decision['bet_correct'] = None
                    decision['bet_profit'] = 0
                
                decision['running_bankroll'] = running_bankroll
                decision['edge_percentile'] = edge_percentiles[idx]
                betting_decisions.append(decision)
            
            for key in betting_decisions[0].keys():
                season_results[key] = [d[key] for d in betting_decisions]
            
            season_results['bet_made'] = season_results['decision'] != 'no_bet'
            
            # Calculate cumulative ROI for Optuna pruning
            all_predictions.append(season_results)
            all_results_so_far = pd.concat(all_predictions, ignore_index=True)
            bets_so_far = all_results_so_far[all_results_so_far['bet_made']]
            
            if len(bets_so_far) > 0:
                total_wagered = bets_so_far['bet_amount'].sum()
                total_profit = bets_so_far['bet_profit'].sum()
                cumulative_roi = (total_profit / total_wagered * 100) if total_wagered > 0 else -100
            else:
                cumulative_roi = -100
            
            cumulative_roi_history.append(cumulative_roi)
            
            # ================================================================
            # OPTUNA PRUNING - Report intermediate results
            # ================================================================
            if self.trial is not None:
                self.trial.report(cumulative_roi, season_idx)
                
                if self.trial.should_prune():
                    if not self.quiet_mode:
                        logger.info(f"  ‚úÇÔ∏è Trial pruned at season {test_season} (ROI: {cumulative_roi:.2f}%)")
                    raise optuna.TrialPruned()
            
            # Update bankroll for next season
            if season_idx < len(test_seasons) - 1:
                season_bankrolls[test_seasons[season_idx + 1]] = running_bankroll
        
        predictions_df = pd.concat(all_predictions, ignore_index=True)
        return predictions_df
    
    def _prepare_features(self, df, numeric_cols, categorical_cols):
        """Prepare features for modeling"""
        existing_numeric = [col for col in numeric_cols if col in df.columns]
        existing_categorical = [col for col in categorical_cols if col in df.columns]
        
        X_numeric = df[existing_numeric].fillna(0).replace([np.inf, -np.inf], 0)
        
        if existing_categorical:
            X_categorical = df[existing_categorical].apply(
                lambda x: x.cat.codes if x.dtype.name == 'category' else 
                pd.Categorical(x).codes
            )
            X = pd.concat([X_numeric, X_categorical], axis=1)
        else:
            X = X_numeric
        
        return X
    
    def run(self, test_seasons=None):
        """Execute the betting pipeline"""
        df = self.load_and_prepare_data()
        feature_cols, numeric_cols, categorical_cols = self.get_feature_columns(df)
        
        predictions_df = self.walk_forward_validation(
            df, feature_cols, numeric_cols, categorical_cols, test_seasons
        )
        
        return predictions_df
    
    def save_models(self, output_path, season):
        """Save trained models and adaptive systems."""
        save_path = Path(output_path) / 'models'
        save_path.mkdir(parents=True, exist_ok=True)
        
        # Save XGBoost models
        if season in self.mean_models:
            self.mean_models[season].save_model(str(save_path / f'mean_model_s{season}.json'))
            self.q16_models[season].save_model(str(save_path / f'q16_model_s{season}.json'))
            self.q84_models[season].save_model(str(save_path / f'q84_model_s{season}.json'))
        
        # Save adaptive systems
        if self.volatility_calibrator.is_fitted:
            joblib.dump(self.volatility_calibrator, save_path / f'vol_calibrator_s{season}.pkl')
        
        if self.push_predictor.is_fitted:
            joblib.dump(self.push_predictor, save_path / f'push_predictor_s{season}.pkl')
        
        # Save conformal quantiles
        if season in self.conformal_quantiles:
            joblib.dump(self.conformal_quantiles[season], save_path / f'conformal_q_s{season}.pkl')
        
        # Save feature importance
        if season in self.feature_importances:
            importance_df = pd.DataFrame([
                {'feature': k, 'importance': v} 
                for k, v in self.feature_importances[season].items()
            ]).sort_values('importance', ascending=False)
            importance_df.to_csv(save_path / f'feature_importance_s{season}.csv', index=False)
        
        logger.info(f"üíæ Models saved to {save_path}")


# ============================================================================
# PARALLEL OPTUNA OPTIMIZATION FRAMEWORK WITH PRUNING
# ============================================================================

def objective(trial, data_path, hpo_seasons):
    """
    Optuna objective function with pruning support.
    Returns metric to MAXIMIZE.
    """
    
    # Suggest parameters with CONSTRAINTS
    min_edge_threshold = trial.suggest_float('min_edge_threshold', 0.035, 0.070)
    max_kelly_fraction = trial.suggest_float('max_kelly_fraction', 0.05, 0.5)
    
    # Uncertainty estimation
    blend_factor = trial.suggest_float('blend_factor', 0.3, 0.9)
    conformal_alpha = trial.suggest_float('conformal_alpha', 0.05, 0.15)
    volatility_multiplier_base = trial.suggest_float('volatility_multiplier_base', 1.2, 2.0)
    
    # Model hyperparameters - MORE PARAMETERS
    max_depth = trial.suggest_int('max_depth', 3, 8)
    learning_rate = trial.suggest_float('learning_rate', 0.01, 0.05)
    n_estimators = trial.suggest_int('n_estimators', 200, 500)
    subsample = trial.suggest_float('subsample', 0.5, 0.9)
    colsample_bytree = trial.suggest_float('colsample_bytree', 0.5, 0.9)
    reg_alpha = trial.suggest_float('reg_alpha', 0.1, 2.0)
    reg_lambda = trial.suggest_float('reg_lambda', 0.1, 2.0)
    min_child_weight = trial.suggest_int('min_child_weight', 20, 100)
    
    # Feature windows - CONSTRAINED
    w1 = trial.suggest_int('window_1', 3, 8)
    w2 = trial.suggest_int('window_2', w1 + 2, 15)
    w3 = trial.suggest_int('window_3', w2 + 2, 25)
    feature_windows = [w1, w2, w3]
    
    # Kelly thresholds - CONSTRAINED (used for initial training only)
    t1 = trial.suggest_float('kelly_edge_threshold_1', 0.045, 0.065)
    t2 = trial.suggest_float('kelly_edge_threshold_2', t1 + 0.01, 0.085)
    t3 = trial.suggest_float('kelly_edge_threshold_3', t2 + 0.01, 0.110)
    
    m1 = trial.suggest_float('kelly_multiplier_1', 0.15, 0.35)
    m2 = trial.suggest_float('kelly_multiplier_2', m1 + 0.05, 0.50)
    m3 = trial.suggest_float('kelly_multiplier_3', m2 + 0.05, 0.75)
    
    # Push predictor fallback window - OPTIMIZABLE
    fallback_push_window = trial.suggest_float('fallback_push_window', 0.25, 0.75)
    
    params = {
        'min_edge_threshold': min_edge_threshold,
        'max_kelly_fraction': max_kelly_fraction,
        'blend_factor': blend_factor,
        'conformal_alpha': conformal_alpha,
        'volatility_multiplier_base': volatility_multiplier_base,
        'max_depth': max_depth,
        'learning_rate': learning_rate,
        'n_estimators': n_estimators,
        'subsample': subsample,
        'colsample_bytree': colsample_bytree,
        'reg_alpha': reg_alpha,
        'reg_lambda': reg_lambda,
        'min_child_weight': min_child_weight,
        'feature_windows': feature_windows,
        'kelly_edge_threshold_1': t1,
        'kelly_edge_threshold_2': t2,
        'kelly_edge_threshold_3': t3,
        'kelly_multiplier_1': m1,
        'kelly_multiplier_2': m2,
        'kelly_multiplier_3': m3,
        'fallback_push_window': fallback_push_window,
    }
    
    # Initialize model with trial for pruning
    model = GPUSpreadBettingModel(
        data_path=data_path,
        output_dir='./optuna_temp',
        initial_bankroll=100,
        trial=trial,  # Pass trial for pruning
        **params
    )
    
    model.set_quiet_mode(True)
    
    try:
        results = model.run(test_seasons=hpo_seasons)
        
        bets_made = results[results['bet_made']].copy()
        
        if len(bets_made) == 0:
            return -100.0
        
        decided_bets = bets_made[bets_made['bet_correct'].notna()]
        
        if len(decided_bets) < 10:
            return -100.0
        
        total_wagered = bets_made['bet_amount'].sum()
        total_profit = bets_made['bet_profit'].sum()
        final_bankroll = results['running_bankroll'].iloc[-1]
        
        roi = total_profit / total_wagered if total_wagered > 0 else -1.0
        
        if final_bankroll <= 0:
            return -100.0
        
        # Optimize Sharpe ratio for risk-adjusted returns
        bet_returns = decided_bets['bet_profit'] / decided_bets['bet_amount']
        sharpe = (bet_returns.mean() / bet_returns.std() * np.sqrt(252)) if bet_returns.std() > 0 else -10.0
        
        # Combine ROI and Sharpe for robust metric
        metric = roi * 100 + sharpe * 10
        
        return metric
        
    except optuna.TrialPruned:
        raise
    except Exception as e:
        logger.error(f"Trial failed: {e}")
        return -100.0


def run_optimization(data_path, n_trials=100, hpo_seasons=None, study_name=None):
    """
    Run Optuna hyperparameter optimization with pruning and sequential execution.
    n_jobs=1 to avoid GPU OOM with multiple processes.
    """
    
    if hpo_seasons is None:
        hpo_seasons = [2019, 2020, 2021, 2022, 2023]
    
    # Create pruner
    pruner = optuna.pruners.MedianPruner(
        n_startup_trials=10,
        n_warmup_steps=2,
        interval_steps=1
    )
    
    study = optuna.create_study(
        direction='maximize',
        study_name=study_name or 'gpu_spread_betting_hpo',
        sampler=optuna.samplers.TPESampler(seed=42),
        pruner=pruner
    )
    
    logger.info(f"\n{'='*80}")
    logger.info(f"üöÄ STARTING GPU-ACCELERATED HPO WITH PRUNING")
    logger.info(f"{'='*80}")
    logger.info(f"Trials: {n_trials}")
    logger.info(f"Parallel Training: 3 models per trial on same GPU")
    logger.info(f"HPO Seasons (validation): {hpo_seasons}")
    logger.info(f"Pruning: Median pruner (stops underperforming trials early)")
    logger.info(f"Objective: Maximize ROI + Sharpe ratio")
    logger.info(f"Device: GPU (CUDA)")
    logger.info(f"{'='*80}\n")
    
    study.optimize(
        lambda trial: objective(trial, data_path, hpo_seasons),
        n_trials=n_trials,
        n_jobs=1,  # Sequential to avoid GPU OOM
        show_progress_bar=True
    )
    
    logger.info(f"\n{'='*80}")
    logger.info(f"üéØ OPTIMIZATION COMPLETE")
    logger.info(f"{'='*80}")
    logger.info(f"Best trial value: {study.best_trial.value:.2f}")
    logger.info(f"Pruned trials: {len([t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED])}/{n_trials}")
    logger.info(f"Best parameters:")
    for key, value in study.best_params.items():
        if isinstance(value, float):
            logger.info(f"  {key}: {value:.4f}")
        else:
            logger.info(f"  {key}: {value}")
    logger.info(f"{'='*80}\n")
    
    return study


def save_optimization_results(study, output_dir='./optuna_results'):
    """Save optimization results and visualizations"""
    output_path = Path(output_dir)
    output_path.mkdir(exist_ok=True)
    
    import pickle
    with open(output_path / 'study.pkl', 'wb') as f:
        pickle.dump(study, f)
    logger.info(f"üíæ Saved study to {output_path / 'study.pkl'}")
    
    import json
    with open(output_path / 'best_params.json', 'w') as f:
        json.dump(study.best_params, f, indent=2)
    logger.info(f"üíæ Saved best params to {output_path / 'best_params.json'}")
    
    try:
        fig1 = plot_optimization_history(study)
        fig1.write_html(str(output_path / 'optimization_history.html'))
        logger.info(f"üìä Saved optimization history")
        
        fig2 = plot_param_importances(study)
        fig2.write_html(str(output_path / 'param_importances.html'))
        logger.info(f"üìä Saved parameter importances")
    except Exception as e:
        logger.warning(f"Could not create visualizations: {e}")
    
    trials_df = study.trials_dataframe()
    trials_df.to_csv(output_path / 'trials_history.csv', index=False)
    logger.info(f"üíæ Saved trials history")


if __name__ == "__main__":
    DATA_PATH = 'feature_output/spread_training_data.parquet'
    
    HPO_VALIDATION_SEASONS = [2019, 2020, 2021, 2022, 2023]
    FINAL_TEST_SEASONS = [2024, 2025]
    
    logger.info(f"\n{'='*80}")
    logger.info("üìä DATA SPLIT STRATEGY")
    logger.info(f"{'='*80}")
    logger.info(f"Training: < 2019 (walk-forward)")
    logger.info(f"HPO Validation: {HPO_VALIDATION_SEASONS}")
    logger.info(f"Final Test (holdout): {FINAL_TEST_SEASONS}")
    logger.info(f"{'='*80}\n")
    
    # logger.info("\nüöÄ RUNNING GPU-ACCELERATED OPTIMIZATION")
    # logger.info("="*80)
    # logger.info("Features:")
    # logger.info("  ‚úÖ Parallel GPU training (3 models simultaneously)")
    # logger.info("  ‚úÖ ML-based Kelly adjustment (no hardcoded thresholds)")
    # logger.info("  ‚úÖ ML-based volatility calibration")
    # logger.info("  ‚úÖ ML-based push prediction")
    # logger.info("  ‚úÖ Optuna pruning (early stopping)")
    # logger.info("  ‚úÖ Risk-adjusted optimization (Sharpe + ROI)")
    # logger.info("="*80 + "\n")
    
    # study = run_optimization(
    #     data_path=DATA_PATH,
    #     n_trials=200,
    #     hpo_seasons=HPO_VALIDATION_SEASONS
    # )
    
    # save_optimization_results(study, output_dir='./optuna_results_gpu')
    
    # 2. LOAD THE SAVED 'best_params.json' INSTEAD
    study_results_dir = Path('./optuna_results_gpu')
    best_params_path = study_results_dir / 'best_params.json'
    
    if not best_params_path.exists():
        logger.error(f"FATAL: 'best_params.json' not found at {best_params_path}")
        logger.error("Please ensure the file exists from your previous run.")
        sys.exit(1) # Exit the script
        
    with open(best_params_path, 'r') as f:
        best_params = json.load(f)
        
    logger.info(f"‚úÖ Loaded best parameters from {best_params_path}")
    # --- END OF MODIFIED BLOCK ---
    
    
    logger.info("\nüß™ FINAL EVALUATION ON HOLDOUT TEST SET")
    logger.info("="*80)
    
    # --- ADD THIS BLOCK TO FIX THE PARAMETERS ---
    try:
        # 3. Transform the window_X keys into the feature_windows list
        best_params['feature_windows'] = [
            best_params.pop('window_1'),
            best_params.pop('window_2'),
            best_params.pop('window_3')
        ]
        logger.info("‚úÖ Transformed 'window_X' params into 'feature_windows' list.")
    except KeyError as e:
        logger.error(f"FATAL: 'best_params.json' is missing a window key ({e}).")
        logger.error("The parameters file might be corrupt or from a different script version.")
        sys.exit(1)
    # --- END OF FIX BLOCK ---

    # 4. Now this initialization will work
    best_model = GPUSpreadBettingModel(
        data_path=DATA_PATH,
        output_dir='./final_test_output_gpu',
        initial_bankroll=100,
        **best_params  # The dictionary is now correct
    )
    best_model.set_quiet_mode(False)
    
    final_results = best_model.run(test_seasons=FINAL_TEST_SEASONS)
    
    final_bets = final_results[final_results['bet_made']].copy()
    final_decided = final_bets[final_bets['bet_correct'].notna()]
    
    if len(final_decided) > 0:
        final_bankroll = final_results['running_bankroll'].iloc[-1]
        total_wagered = final_bets['bet_amount'].sum()
        total_profit = final_bets['bet_profit'].sum()
        final_roi = (total_profit / total_wagered * 100) if total_wagered > 0 else 0
        
        wins = final_decided['bet_correct'].sum()
        win_rate = wins / len(final_decided)
        
        bet_returns = final_decided['bet_profit'] / final_decided['bet_amount']
        final_sharpe = (bet_returns.mean() / bet_returns.std() * np.sqrt(252)) if bet_returns.std() > 0 else 0
        
        logger.info(f"\n{'='*80}")
        logger.info("üèÜ FINAL HOLDOUT TEST RESULTS")
        logger.info(f"{'='*80}")
        logger.info(f"Seasons: {FINAL_TEST_SEASONS}")
        logger.info(f"Initial Bankroll: $100.00")
        logger.info(f"Final Bankroll: ${final_bankroll:,.2f}")
        logger.info(f"Total Return: {((final_bankroll - 100) / 100 * 100):+.1f}%")
        logger.info(f"ROI: {final_roi:+.2f}%")
        logger.info(f"Win Rate: {win_rate:.1%}")
        logger.info(f"Sharpe Ratio: {final_sharpe:.2f}")
        logger.info(f"Total Bets: {len(final_bets)}")
        logger.info(f"{'='*80}\n")
    
    # Save final predictions
    final_results.to_parquet('./final_test_output_gpu/holdout_predictions.parquet', index=False)
    logger.info("üíæ Saved holdout predictions\n")
    
    # Save final models and adaptive systems
    logger.info("üíæ Saving final trained models and ML systems...")
    for season in FINAL_TEST_SEASONS:
        best_model.save_models('./final_test_output_gpu', season)
    
    # Generate feature importance report
    logger.info("\nüìä FEATURE IMPORTANCE ANALYSIS")
    logger.info("="*80)
    for season in FINAL_TEST_SEASONS:
        if season in best_model.feature_importances:
            importance = best_model.feature_importances[season]
            sorted_features = sorted(importance.items(), key=lambda x: x[1], reverse=True)[:15]
            logger.info(f"\nTop 15 features for season {season}:")
            for idx, (feat, imp) in enumerate(sorted_features, 1):
                logger.info(f"  {idx:2d}. {feat:40s} {imp:10.1f}")
            
            # Generate visual plot
            try:
                importance_df = pd.DataFrame(
                    importance.items(), 
                    columns=['Feature', 'Gain']
                ).sort_values(by='Gain', ascending=False)
                
                plt.figure(figsize=(12, 10))
                sns.barplot(
                    x='Gain', 
                    y='Feature', 
                    data=importance_df.head(20),  # Plot top 20
                    palette='viridis'
                )
                plt.title(f'Feature Importance (Gain) - Season {season}', fontsize=16, fontweight='bold')
                plt.xlabel('Gain', fontsize=12)
                plt.ylabel('Feature', fontsize=12)
                plt.tight_layout()
                
                save_path = Path(best_model.output_dir) / 'models' / f'feature_importance_s{season}.png'
                plt.savefig(save_path, dpi=150, bbox_inches='tight')
                plt.close()
                logger.info(f"  üìä Saved feature importance plot to {save_path}")
            except Exception as e:
                logger.warning(f"  Could not generate feature importance plot: {e}")
    
    logger.info("="*80 + "\n")
    
    # Analyze ML system effectiveness
    logger.info("\nü§ñ ML ADAPTIVE SYSTEMS STATUS")
    logger.info("="*80)
    logger.info(f"Volatility Calibrator: {'‚úÖ TRAINED' if best_model.volatility_calibrator.is_fitted else '‚ö†Ô∏è  NOT TRAINED'}")
    logger.info(f"Push Predictor: {'‚úÖ TRAINED' if best_model.push_predictor.is_fitted else '‚ö†Ô∏è  NOT TRAINED'}")
    logger.info("\nüí° Note: Kelly adjustment uses HPO-optimized parametric thresholds")
    logger.info("   (More robust than ML for this problem - thresholds found by Optuna)")
    
    if best_model.volatility_calibrator.is_fitted:
        logger.info("\nüí° Volatility Calibrator Details:")
        logger.info(f"  XGBoost classifier trained on ALL validation history")
        logger.info(f"  Multi-season training reduces overfitting risk")
        logger.info(f"  Provides season-level volatility multiplier")
    
    if best_model.push_predictor.is_fitted:
        logger.info("\nüí° Push Predictor Details:")
        logger.info(f"  XGBoost classifier for push probability")
        logger.info(f"  Trained on ALL historical data (multi-season)")
        logger.info(f"  Fallback uses HPO-optimized push_window: {best_model.fallback_push_window:.3f}")
        logger.info(f"  Replaces hardcoded push calculation")
    
    logger.info("="*80 + "\n")
    
    # Calculate performance metrics breakdown
    logger.info("\nüìà DETAILED PERFORMANCE BREAKDOWN")
    logger.info("="*80)
    
    for season in FINAL_TEST_SEASONS:
        season_data = final_results[final_results['season'] == season]
        season_bets = season_data[season_data['bet_made']]
        season_decided = season_bets[season_bets['bet_correct'].notna()]
        
        if len(season_decided) > 0:
            season_profit = season_bets['bet_profit'].sum()
            season_wagered = season_bets['bet_amount'].sum()
            season_roi = (season_profit / season_wagered * 100) if season_wagered > 0 else 0
            season_wins = season_decided['bet_correct'].sum()
            season_win_rate = season_wins / len(season_decided)
            
            logger.info(f"\nSeason {season}:")
            logger.info(f"  Bets: {len(season_decided)}")
            logger.info(f"  Win Rate: {season_win_rate:.1%}")
            logger.info(f"  ROI: {season_roi:+.2f}%")
            logger.info(f"  Profit: ${season_profit:+.2f}")
    
    logger.info("\n" + "="*80 + "\n")
    
    # Betting behavior analysis
    logger.info("üìä BETTING BEHAVIOR ANALYSIS")
    logger.info("="*80)
    
    bet_sizes = final_bets['bet_amount']
    kelly_fractions = final_bets['kelly_fraction']
    kelly_multipliers = final_bets['kelly_multiplier']
    edges = final_bets['edge']
    
    logger.info(f"\nBet Sizing Statistics:")
    logger.info(f"  Mean bet size: ${bet_sizes.mean():.2f}")
    logger.info(f"  Median bet size: ${bet_sizes.median():.2f}")
    logger.info(f"  Min bet size: ${bet_sizes.min():.2f}")
    logger.info(f"  Max bet size: ${bet_sizes.max():.2f}")
    
    logger.info(f"\nKelly Fraction Statistics:")
    logger.info(f"  Mean Kelly fraction: {kelly_fractions.mean():.4f}")
    logger.info(f"  Max Kelly fraction: {kelly_fractions.max():.4f}")
    
    logger.info(f"\nKelly Multiplier Statistics:")
    logger.info(f"  Mean multiplier: {kelly_multipliers.mean():.3f}")
    logger.info(f"  Median multiplier: {kelly_multipliers.median():.3f}")
    logger.info(f"  Min multiplier: {kelly_multipliers.min():.3f}")
    logger.info(f"  Max multiplier: {kelly_multipliers.max():.3f}")
    
    logger.info(f"\nEdge Statistics:")
    logger.info(f"  Mean edge: {edges.mean()*100:.2f}%")
    logger.info(f"  Median edge: {edges.median()*100:.2f}%")
    logger.info(f"  Min edge: {edges.min()*100:.2f}%")
    logger.info(f"  Max edge: {edges.max()*100:.2f}%")
    
    logger.info("\n" + "="*80 + "\n")
    
    # Risk analysis
    logger.info("‚ö†Ô∏è  RISK ANALYSIS")
    logger.info("="*80)
    
    bankroll_history = final_results['running_bankroll'].values
    peak_bankroll = bankroll_history.max()
    trough_bankroll = bankroll_history.min()
    max_drawdown = (peak_bankroll - trough_bankroll) / peak_bankroll if peak_bankroll > 0 else 0
    
    logger.info(f"\nBankroll Statistics:")
    logger.info(f"  Starting: ${best_model.initial_bankroll:.2f}")
    logger.info(f"  Peak: ${peak_bankroll:.2f}")
    logger.info(f"  Trough: ${trough_bankroll:.2f}")
    logger.info(f"  Final: ${final_bankroll:.2f}")
    logger.info(f"  Max Drawdown: {max_drawdown*100:.1f}%")
    
    # Calculate Calmar ratio
    if max_drawdown > 0:
        calmar_ratio = ((final_bankroll - 100) / 100) / max_drawdown
        logger.info(f"  Calmar Ratio: {calmar_ratio:.2f}")
    
    # Calculate consecutive loss streaks
    consecutive_losses = 0
    max_loss_streak = 0
    for bet in final_decided.itertuples():
        if not bet.bet_correct:
            consecutive_losses += 1
            max_loss_streak = max(max_loss_streak, consecutive_losses)
        else:
            consecutive_losses = 0
    
    logger.info(f"\nRisk Metrics:")
    logger.info(f"  Max consecutive losses: {max_loss_streak}")
    logger.info(f"  Volatility (std of returns): {bet_returns.std():.3f}")
    logger.info(f"  Downside deviation: {bet_returns[bet_returns < 0].std():.3f}")
    
    # Sortino ratio (like Sharpe but only penalizes downside volatility)
    downside_std = bet_returns[bet_returns < 0].std()
    if downside_std > 0:
        sortino = (bet_returns.mean() / downside_std * np.sqrt(252))
        logger.info(f"  Sortino Ratio: {sortino:.2f}")
    
    logger.info("\n" + "="*80 + "\n")
    
    # Edge distribution analysis
    logger.info("üìä EDGE DISTRIBUTION ANALYSIS")
    logger.info("="*80)
    
    edge_bins = pd.cut(edges * 100, bins=[0, 3, 4, 5, 6, 8, 100])
    edge_analysis = final_decided.groupby(edge_bins, observed=True).agg({
        'bet_correct': ['count', 'sum', 'mean'],
        'bet_profit': 'sum',
        'bet_amount': 'sum'
    })
    
    logger.info("\nPerformance by Edge Size:")
    logger.info(f"{'Edge Range':<15} {'Bets':<8} {'Wins':<8} {'Win%':<10} {'ROI%':<10}")
    logger.info("-" * 60)
    
    for idx, row in edge_analysis.iterrows():
        n_bets = int(row[('bet_correct', 'count')])
        n_wins = int(row[('bet_correct', 'sum')])
        win_rate = row[('bet_correct', 'mean')]
        profit = row[('bet_profit', 'sum')]
        wagered = row[('bet_amount', 'sum')]
        roi = (profit / wagered * 100) if wagered > 0 else 0
        
        logger.info(f"{str(idx):<15} {n_bets:<8} {n_wins:<8} {win_rate*100:<10.1f} {roi:<10.2f}")
    
    logger.info("\n" + "="*80 + "\n")
    
    # Compare ML vs parametric Kelly (removed - using HPO-optimized parametric only)
    
    # Push prediction analysis
    if best_model.push_predictor.is_fitted:
        logger.info("üéØ PUSH PREDICTION ANALYSIS")
        logger.info("="*80)
        
        predicted_pushes = final_results[final_results['push_prob'] > 0.1]
        actual_pushes = final_results[final_results['is_push'] == 1]
        
        logger.info(f"\nActual pushes: {len(actual_pushes)}")
        logger.info(f"High push probability predictions (>10%): {len(predicted_pushes)}")
        
        if len(actual_pushes) > 0:
            avg_push_prob_on_pushes = actual_pushes['push_prob'].mean()
            avg_push_prob_on_non_pushes = final_results[final_results['is_push'] == 0]['push_prob'].mean()
            
            logger.info(f"Avg push prob on actual pushes: {avg_push_prob_on_pushes*100:.2f}%")
            logger.info(f"Avg push prob on non-pushes: {avg_push_prob_on_non_pushes*100:.2f}%")
            logger.info(f"Discrimination power: {(avg_push_prob_on_pushes - avg_push_prob_on_non_pushes)*100:.2f}%")
        
        logger.info("\n" + "="*80 + "\n")
    
    # Final summary
    logger.info(f"\n{'='*80}")
    logger.info("‚úÖ COMPLETE ANALYSIS FINISHED")
    logger.info(f"{'='*80}")
    logger.info("\nüìÅ Output Files Generated:")
    logger.info("  ‚úÖ optuna_results_gpu/study.pkl - Full optimization study")
    logger.info("  ‚úÖ optuna_results_gpu/best_params.json - Best hyperparameters")
    logger.info("  ‚úÖ optuna_results_gpu/trials_history.csv - All trial results")
    logger.info("  ‚úÖ optuna_results_gpu/optimization_history.html - Interactive plot")
    logger.info("  ‚úÖ optuna_results_gpu/param_importances.html - Parameter importance")
    logger.info("  ‚úÖ final_test_output_gpu/holdout_predictions.parquet - Test predictions")
    logger.info("  ‚úÖ final_test_output_gpu/models/ - Trained XGBoost models")
    logger.info("  ‚úÖ final_test_output_gpu/models/ - ML adaptive systems (Vol, Push)")
    logger.info("  ‚úÖ final_test_output_gpu/models/feature_importance_*.csv - Feature rankings")
    logger.info("  ‚úÖ final_test_output_gpu/models/feature_importance_*.png - Visual plots")
    
    logger.info("\nüéØ Key Achievements:")
    logger.info("  ‚úÖ HPO-optimized Kelly thresholds (more robust than ML)")
    logger.info("  ‚úÖ Multi-season ML training (Vol/Push) - reduced overfitting")
    logger.info("  ‚úÖ HPO-optimized push_window fallback")
    logger.info("  ‚úÖ Parallel GPU training (3 models simultaneously)")
    logger.info("  ‚úÖ Optuna pruning (early stopping of bad trials)")
    logger.info("  ‚úÖ Risk-adjusted optimization (ROI + Sharpe)")
    logger.info("  ‚úÖ Feature importance tracking + visualization")
    logger.info("  ‚úÖ Comprehensive performance analysis")
    
    logger.info("\n‚ö†Ô∏è  CRITICAL REMINDERS:")
    logger.info("  1. Final holdout ROI is the ONLY unbiased metric")
    logger.info("  2. HPO validation performance is optimistically biased")
    logger.info("  3. ML adaptive systems now trained on multi-season data")
    logger.info("  4. Volatility/Push calibrators more stable than single-season")
    logger.info("  5. Kelly adjustment uses HPO-optimized thresholds (proven robust)")
    logger.info("  6. Retrain when market conditions change significantly")
    
    logger.info("\nüìà Next Steps:")
    logger.info("  1. Review feature_importance_*.png for visual analysis")
    logger.info("  2. Analyze edge distribution - are high-edge bets performing?")
    logger.info("  3. Compare Vol/Push ML systems vs baseline (run A/B test)")
    logger.info("  4. Run stability test to verify parameter robustness")
    logger.info("  5. Multi-season training makes adaptive systems more reliable")
    logger.info("  6. Consider ensemble methods for even better predictions")
    logger.info("  7. Implement real-time monitoring dashboard")
    
    logger.info(f"\n{'='*80}\n")